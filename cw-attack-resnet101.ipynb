{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install gdown","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!gdown https://drive.google.com/uc?id=1-7z0lFddFDcy97On7vO5MlucFUiFJYi1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport json\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as Data\n\nimport torchvision.utils\nfrom torchvision import models\nimport torchvision.datasets as dsets\nimport torchvision.transforms as transforms","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load data\ndata = torch.load('lab_img.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set device\nuse_cuda = True\ndevice = torch.device(\"cuda\" if use_cuda and torch.cuda.is_available() else \"cpu\")\nprint('device', device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load resnet101\nmodel = models.resnet101(pretrained=True)\n\n# use cuda if available\nif torch.cuda.is_available():\n    model.cuda()\n\nmodel = model.eval()\n\nprint('use cuda', torch.cuda.is_available())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test clean accuracy\ntotal = 0\ncorrect = 0\nfor d in data:\n    lab, img = d\n    lab, img = lab.cuda(), img.cuda()\n    output = model(img)\n    _, pre = torch.max(output.data, 1)\n    total += 1\n    if pre == lab:\n        correct += 1\nprint('clean accuracy', correct/total)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CW-L2 Attack\n# Based on the paper, i.e. not exact same version of the code on https://github.com/carlini/nn_robust_attacks\n# (1) Binary search method for c, (2) Optimization on tanh space, (3) Choosing method best l2 adversaries is NOT IN THIS CODE.\ndef cw_l2_attack(model, images, labels, targeted=False, c=1e-4, kappa=0, max_iter=1000, learning_rate=0.01) :\n\n    images = images.to(device)     \n    labels = labels.to(device)\n\n    # Define f-function\n    def f(x) :\n\n        outputs = model(x)\n        one_hot_labels = torch.eye(len(outputs[0]))[labels].to(device)\n\n        i, _ = torch.max((1-one_hot_labels)*outputs, dim=1)\n        j = torch.masked_select(outputs, one_hot_labels.byte())\n        \n        # If targeted, optimize for making the other class most likely \n        if targeted :\n            return torch.clamp(i-j, min=-kappa)\n        \n        # If untargeted, optimize for making the other class most likely \n        else :\n            return torch.clamp(j-i, min=-kappa)\n    \n    w = torch.zeros_like(images, requires_grad=True).to(device)\n\n    optimizer = optim.Adam([w], lr=learning_rate)\n\n    prev = 1e10\n    \n    for step in range(max_iter) :\n\n        a = 1/2*(nn.Tanh()(w) + 1)\n\n        loss1 = nn.MSELoss(reduction='sum')(a, images)\n        loss2 = torch.sum(c*f(a))\n\n        cost = loss1 + loss2\n\n        optimizer.zero_grad()\n        cost.backward()\n        optimizer.step()\n\n        # Early Stop when loss does not converge.\n        if step % (max_iter//10) == 0 :\n            if cost > prev :\n                print('Attack Stopped due to CONVERGENCE....')\n                return a\n            prev = cost\n        \n        print('- Learning Progress : %2.2f %%        ' %((step+1)/max_iter*100), end='\\r')\n\n    attack_images = 1/2*(nn.Tanh()(w) + 1)\n\n    return attack_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct = 0\ntotal = 0\nadvs = []\n\nfor lab, img in data:\n    adv = cw_l2_attack(model, img, lab, targeted=False, c=0.1)\n    lab = lab.to(device)\n    outputs = model(adv)\n    _, pre = torch.max(outputs.data, 1)\n    \n    total += 1\n    correct += (pre == lab).sum()\n    \n    advs.append([lab, adv])\n\nprint('robust accuracy', (correct / total).item())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show some clean examples\nimport matplotlib.pyplot as plt\ncnt = 0\nplt.figure(figsize=(8,10))\nfor i in range(4):\n    for j in range(4):\n        cnt += 1\n        plt.subplot(4, 4,cnt)\n        plt.xticks([], [])\n        plt.yticks([], [])\n        img = data[i*4+j][1][0].cpu().permute(1,2,0)\n        plt.imshow(img, cmap=\"gray\")\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show some adv examples\nimport matplotlib.pyplot as plt\ncnt = 0\nplt.figure(figsize=(8,10))\nfor i in range(4):\n    for j in range(4):\n        cnt += 1\n        plt.subplot(4, 4,cnt)\n        plt.xticks([], [])\n        plt.yticks([], [])\n        img = advs[i*4+j][1][0].cpu().permute(1,2,0)\n        plt.imshow(img.detach().numpy(), cmap=\"gray\")\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(advs, 'cw-resnet101-advs.pt')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}